{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import findspark\n",
    "#findspark.init('/home/max/Downloads/spark-2.4.0-bin-hadoop2.7')\n",
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark.sql import Row\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark= SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import csv\n",
    "import sys\n",
    "from pympler.asizeof import asizeof\n",
    "import boto3\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import code counts, and convert to dict with probabilities\n",
    "code_counts = pd.read_csv('code_counts.csv')\n",
    "code_counts.columns = ['code', 'count']\n",
    "code_counts['prop'] = code_counts['count']/code_counts['count'].sum()\n",
    "#code_counts.head()\n",
    "code_counts = dict(zip(code_counts['code'], code_counts['prop']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_codes = list(code_counts.keys())\n",
    "#print(list(unique_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D04'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get random code based on the weight (probability) of each code\n",
    "def get_random_code(dct):\n",
    "    rand_val = random.random()\n",
    "    total = 0\n",
    "    for k, v in dct.items():\n",
    "        total += v\n",
    "        if rand_val <= total:\n",
    "            return k\n",
    "    assert False, 'unreachable'\n",
    "    \n",
    "get_random_code(code_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "filesize = 120000000 # 120mb\n",
    "max_size = 1000000000 # 1gb\n",
    "total_files = max_size/filesize\n",
    "print(int(total_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing 50.0 MB in each file, in a total of 2 files\n",
      "0 64\n",
      "10000 8697464\n",
      "20000 35746776\n"
     ]
    }
   ],
   "source": [
    "start_value = 5\n",
    "start_time_shift =20\n",
    "random_walk_weight = 0.01\n",
    "random_walk_variance = 1\n",
    "seasonality_1_freq = 50 #lower is shorter\n",
    "seasonality_1_weight = 5\n",
    "seasonality_2_freq = 7 #lower is shorter\n",
    "seasonality_2_weight = 2\n",
    "\n",
    "num_words_in_text = 100 # number of words in each patent text\n",
    "\n",
    "sample_size = 1000\n",
    "\n",
    "trend = 0.02\n",
    "exponent = 1\n",
    "n_samples = 10\n",
    "bucket_name = 'patents-bucket'\n",
    "\n",
    "times = [0,0,0,0,0,0]\n",
    "\n",
    "terms = []\n",
    "with open('wordlist.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    terms = [word[0] for word in list(reader)]\n",
    "    random.shuffle(terms)\n",
    "        \n",
    "# store dataframe to S3 in CSV format\n",
    "def store_data(df, file_num):\n",
    "    csv_buffer = StringIO()\n",
    "    df.to_csv(csv_buffer, index=False)\n",
    "    s3_resource = boto3.resource('s3')\n",
    "    s3_resource.Object(bucket_name, 'patent-100mbs/patents_'+str(file_num)+'.csv').put(Body=csv_buffer.getvalue())\n",
    "\n",
    "# Get number of samples to be made for one day\n",
    "def get_num_samples(base):\n",
    "    #Assume no start at y = 0\n",
    "    random_walk = np.random.normal(0,random_walk_variance)\n",
    "    time = base + start_time_shift\n",
    "\n",
    "    y = (np.sin(time/seasonality_1_freq))*seasonality_1_weight #Add seasonality 1\n",
    "    y = y + np.sin(time/seasonality_2_freq)*seasonality_2_weight #Add seasonality 2\n",
    "    y = y + (trend * (time ** exponent)) #Add trend\n",
    "\n",
    "    # Random walk component\n",
    "    random_walk += np.random.normal(0,random_walk_variance)\n",
    "    \n",
    "    return max(0, y + random_walk * random_walk_weight)\n",
    "\n",
    "\n",
    "def create_datasets(filesize, max_files):\n",
    "    print(\"Storing\", filesize/1000000, \"MB in each file, in a total of\", max_files, \"files\")\n",
    "    rows = []\n",
    "    sample_range = 0\n",
    "    file_num = 0\n",
    "    \n",
    "    i = 0\n",
    "    while file_num < max_files:\n",
    "        if i%10000 == 0:\n",
    "            print(i, sys.getsizeof(rows))\n",
    "        \n",
    "        #s1 = time.time()    \n",
    "        if sys.getsizeof(rows) > filesize: # larger than filesize (120mb?), store file\n",
    "            df = pd.DataFrame(rows, columns=['date', 'code', 'text'])\n",
    "            #print(\"stored\", sys.getsizeof(rows)/1000000, \"MB in file num\", file_num)\n",
    "            store_data(df, file_num)\n",
    "            print(\"stored\", sys.getsizeof(rows)/1000000, \"MB in file num\", file_num)\n",
    "            rows = []\n",
    "            file_num+=1\n",
    "        #e1 = time.time()\n",
    "        #times[3] += e1-s1\n",
    "            \n",
    "        #s2 = time.time()  \n",
    "        num_samples = get_num_samples(i)\n",
    "        #e2 = time.time()\n",
    "        #times[4] += e2-s2\n",
    "        \n",
    "        #s3 = time.time()\n",
    "        for n in range(int(round(num_samples))): #Create n entries\n",
    "            #s = time.time()\n",
    "            date = datetime.datetime(1950, 1, 1, 0, 0) + timedelta(days=int(i))\n",
    "            current_sample = i+n\n",
    "            #e = time.time()\n",
    "            #times[0] += e-s\n",
    "            #sample = terms[current_sample:current_sample+100]\n",
    "            #text = \" \".join(random.sample(terms, num_words_in_text)) # TOO SLOW\n",
    "            #s = time.time()\n",
    "            rnd = random.randint(1,len(terms)-101)\n",
    "            text = \" \".join(terms[rnd:rnd+100])\n",
    "            #e = time.time()\n",
    "            #times[1] += e-s\n",
    "            #s = time.time()\n",
    "            #rows.append([date, get_random_code(code_counts), text])\n",
    "            \n",
    "            rows.append([date, random.choice(unique_codes), text])\n",
    "            #e = time.time()\n",
    "            #times[2] += e-s\n",
    "        #e3 = time.time()\n",
    "        #times[2] += e3-s3\n",
    "        \n",
    "        \n",
    "        \n",
    "        i+=1\n",
    "\n",
    "filesize = 50000000 # 50mb\n",
    "#max_total_size = 1000000000 # 1gb\n",
    "max_total_size = 100000000\n",
    "#filesize = 1200 #\n",
    "#max_total_size = 4000 #\n",
    "max_files = int(max_total_size/filesize)\n",
    "#filesize=12000\n",
    "create_datasets(filesize, max_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd = random.randint(1,len(unique_codes))\n",
    "rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.536070108413696\n"
     ]
    }
   ],
   "source": [
    "           \n",
    "s = time.time()\n",
    "for i in range(10000000):\n",
    "    rnd = random.randint(1,len(terms)-101)\n",
    "    terms[rnd:rnd+100]\n",
    "e = time.time()\n",
    "print( e-s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
