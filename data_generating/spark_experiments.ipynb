{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/max/Downloads/spark-2.4.0-bin-hadoop2.7')\n",
    "from pyspark.sql import SparkSession\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark= SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date code                                               text\n",
      "0      2000-01-01    a  tba smoke weblogs rfc auditor pressure quotati...\n",
      "1      2000-01-01    a  smoke weblogs rfc auditor pressure quotations ...\n",
      "2      2000-01-01    a  weblogs rfc auditor pressure quotations aye af...\n",
      "3      2000-01-02    a  smoke weblogs rfc auditor pressure quotations ...\n",
      "4      2000-01-02    a  weblogs rfc auditor pressure quotations aye af...\n",
      "5      2000-01-02    a  rfc auditor pressure quotations aye afterwards...\n",
      "6      2000-01-03    a  weblogs rfc auditor pressure quotations aye af...\n",
      "7      2000-01-03    a  rfc auditor pressure quotations aye afterwards...\n",
      "8      2000-01-03    a  auditor pressure quotations aye afterwards com...\n",
      "9      2000-01-04    a  rfc auditor pressure quotations aye afterwards...\n",
      "10     2000-01-04    a  auditor pressure quotations aye afterwards com...\n",
      "11     2000-01-05    a  auditor pressure quotations aye afterwards com...\n",
      "12     2000-01-05    a  pressure quotations aye afterwards compared at...\n",
      "13     2000-01-06    a  pressure quotations aye afterwards compared at...\n",
      "14     2000-01-06    a  quotations aye afterwards compared athens fals...\n",
      "15     2000-01-07    a  quotations aye afterwards compared athens fals...\n",
      "16     2000-01-07    a  aye afterwards compared athens false travel so...\n",
      "17     2000-01-08    a  aye afterwards compared athens false travel so...\n",
      "18     2000-01-08    a  afterwards compared athens false travel soldie...\n",
      "19     2000-01-09    a  afterwards compared athens false travel soldie...\n",
      "20     2000-01-09    a  compared athens false travel soldiers follow o...\n",
      "21     2000-01-10    a  compared athens false travel soldiers follow o...\n",
      "22     2000-01-10    a  athens false travel soldiers follow objective ...\n",
      "23     2000-01-11    a  athens false travel soldiers follow objective ...\n",
      "24     2000-01-11    a  false travel soldiers follow objective oclc ad...\n",
      "25     2000-01-12    a  false travel soldiers follow objective oclc ad...\n",
      "26     2000-01-12    a  travel soldiers follow objective oclc addition...\n",
      "27     2000-01-13    a  travel soldiers follow objective oclc addition...\n",
      "28     2000-01-13    a  soldiers follow objective oclc additions sugge...\n",
      "29     2000-01-14    a  soldiers follow objective oclc additions sugge...\n",
      "...           ...  ...                                                ...\n",
      "105506 2002-09-25    j  lawyers ho lake staying conversations separati...\n",
      "105507 2002-09-25    j  ho lake staying conversations separation readi...\n",
      "105508 2002-09-25    j  lake staying conversations separation readily ...\n",
      "105509 2002-09-26    j  broader yard getting buyers jam awesome differ...\n",
      "105510 2002-09-26    j  yard getting buyers jam awesome differ america...\n",
      "105511 2002-09-26    j  getting buyers jam awesome differ america caut...\n",
      "105512 2002-09-26    j  buyers jam awesome differ america caution shor...\n",
      "105513 2002-09-26    j  jam awesome differ america caution short endle...\n",
      "105514 2002-09-26    j  awesome differ america caution short endless c...\n",
      "105515 2002-09-26    j  differ america caution short endless credit ma...\n",
      "105516 2002-09-26    j  america caution short endless credit magnitude...\n",
      "105517 2002-09-26    j  caution short endless credit magnitude scales ...\n",
      "105518 2002-09-26    j  short endless credit magnitude scales groups p...\n",
      "105519 2002-09-26    j  endless credit magnitude scales groups plannin...\n",
      "105520 2002-09-26    j  credit magnitude scales groups planning rebel ...\n",
      "105521 2002-09-26    j  magnitude scales groups planning rebel pole dk...\n",
      "105522 2002-09-26    j  scales groups planning rebel pole dk clearing ...\n",
      "105523 2002-09-26    j  groups planning rebel pole dk clearing weekend...\n",
      "105524 2002-09-26    j  planning rebel pole dk clearing weekend constr...\n",
      "105525 2002-09-26    j  rebel pole dk clearing weekend constraints che...\n",
      "105526 2002-09-26    j  pole dk clearing weekend constraints cheap law...\n",
      "105527 2002-09-26    j  dk clearing weekend constraints cheap lawyers ...\n",
      "105528 2002-09-26    j  clearing weekend constraints cheap lawyers ho ...\n",
      "105529 2002-09-26    j  weekend constraints cheap lawyers ho lake stay...\n",
      "105530 2002-09-26    j  constraints cheap lawyers ho lake staying conv...\n",
      "105531 2002-09-26    j  cheap lawyers ho lake staying conversations se...\n",
      "105532 2002-09-26    j  lawyers ho lake staying conversations separati...\n",
      "105533 2002-09-26    j  ho lake staying conversations separation readi...\n",
      "105534 2002-09-26    j  lake staying conversations separation readily ...\n",
      "105535 2002-09-26    j  staying conversations separation readily nothi...\n",
      "\n",
      "[105536 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "%run generate_data.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(dummy_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.parquet(\"test2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.csv(\"test2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
